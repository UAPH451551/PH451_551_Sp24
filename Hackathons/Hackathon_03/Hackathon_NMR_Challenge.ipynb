{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UAPH451551/PH451_551_Sp24/blob/main/Hackathons/Hackathon_03/Hackathon_NMR_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-lmbBG-eMk6"
      },
      "source": [
        "# Hackathon - NMR Challenge\n",
        "\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "- Nuclear Magnetic Resonance (NMR) is an experimental technique that allows for<br>\n",
        "the control and measurement of nuclear spins in crystals and molecules.<br>\n",
        "- A common \"recipe\" for NMR is called the spin echo: the spins start aligned,<br>\n",
        "begin to disperse, and are then refocused. This creates a sharp peak, or<br> \"echo\", in the net magnetization $M$ of the material at a later time. When the<br>\n",
        "spins interact with each other, this refocused echo can become highly distorted.<br>\n",
        "- Materials with strong electron-electron couplings have a variety of<br> applications, from superconductivity to ferromagnetism. They also tend to<br> enhance the nuclear spin-spin couplings, allowing NMR to act as a probe of <br> these important systems.<br>\n",
        "- Design and train a model that predicts the strength and shape of interactions<br>\n",
        "between the nuclear spins from simulated time-dependent magnetization curves,<br>\n",
        "$M(t)$.\n",
        "\n",
        "Before getting to any code, we first review the structure of this machine<br> learning problem and introduce some of the details of the underlying physics we<br>\n",
        "are trying to capture.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Theory For Those Interested"
      ],
      "metadata": {
        "id": "esMV0INGNEwu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdQI7vD8eMk7"
      },
      "source": [
        "## Quick description of the ML problem\n",
        "\n",
        "### Goal:\n",
        "Predict three real numbers from an input vector of complex numbers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TchvASHYeMk7"
      },
      "source": [
        "## Introduction to NMR and spin echos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_fOfvYeMk8"
      },
      "source": [
        "Although the NMR \"spin echo\" technique may sound complicated, the following <br> animation created by Gavin W Morley (by way of <br>\n",
        "https://en.wikipedia.org/wiki/Spin_echo) makes it much clearer!\n",
        "\n",
        "\n",
        "![NMR Spin Echo Animation](https://upload.wikimedia.org/wikipedia/commons/9/9b/HahnEcho_GWM.gif)\n",
        "\n",
        "\n",
        "The red arrows in this animation represents the values of nuclear spins in the <br>\n",
        "material.\n",
        "\n",
        "They all begin in the same direction (up), and then an applied magnetic field<br>\n",
        "rotates them into the x-y plane (indicated by the 90$^\\circ$ pulse).<br>\n",
        "A constant external magnetic field in the z-direction did not affect the spins <br>\n",
        "when they were pointing \"up\", but now that they lie in the x-y plane they begin <br>\n",
        "to precess.\n",
        "\n",
        "\n",
        "Because each nuclear spin sits in a slightly different magnetic environment, <br>\n",
        "each one has a slightly different response to the background z-direction <br> magnetic field, causing some to precess in a clockwise direction and others in <br>\n",
        "a counterclockwise direction.\n",
        "\n",
        "\n",
        "After a fixed amount of time, $t$ in the above animation, a second magnetic <br>\n",
        "pulse is applied and rotates each spin 180$^\\circ$ in the x-y plane. <br>\n",
        "After this, the spins continue to move as they did before, but because of the <br>\n",
        "180$^\\circ$ pulse they are now effectively precessing  \"backwards\" compared to <br>\n",
        "the original motion!<br>\n",
        "So after an additional time $t$ passes, the variations in precession time is <br>\n",
        "canceled out, causing a refocusing of the spins.\n",
        "\n",
        "This shows up as a measurable \"echo\" in the average spin magnetization of the <br>\n",
        "material, and can be measured in experiments. <br>\n",
        "This is an important technique because the average spin magnetization is hard <br>\n",
        "to measure during an applied \"pulse\", but there is no external pulse during the <br>\n",
        "\"echo\", allowing for accurate measurement of the peak value and decay shape.\n",
        "\n",
        "Here is a typical curve for the time-dependent magnetization $M(t)$ for a <br> spin-echo in most materials:\n",
        "\n",
        "![standard_spinecho.png](https://raw.githubusercontent.com/UAPH451551/PH451_551_Sp24_private/main/Hackathons/Hackathon_03/standard_spinecho.png?token=GHSAT0AAAAAACJHQOSSHS6YUD4LFXLVRE56ZQTCYSQ)\n",
        "\n",
        "Sometimes, a more complicated curve can occur, such as:\n",
        "\n",
        "![coupled_echo.png](https://raw.githubusercontent.com/UAPH451551/PH451_551_Sp24_private/main/Hackathons/Hackathon_03/coupled_echo.png?token=GHSAT0AAAAAACJHQOSTN7N5H5P2MAY4OLKAZQTCYHQ)\n",
        "\n",
        "This more complicated structure has been caused by spin-spin interactions <br>\n",
        "between the precessing nuclear spins. Normally, each spin precesses in a<br> uniform way irrespective of the rest of the nuclei in the material. In this <br>\n",
        "coupled case, however, the nuclear magnetization that occurs near the \"echo\" <br>\n",
        "influences the spins' motions, modifying the shape of the observed echo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkGF2ySheMk8"
      },
      "source": [
        "## Electronic and nuclear spins\n",
        "\n",
        "Most materials can be classified by their electronic properties into three <br> categories: metal, insulator, and semiconductor. <br>\n",
        "These terms are based on a semi-classical description of the electrons in a <br>\n",
        "crystal.<br>\n",
        "The electrons are treated as a collection of classical particles, with energies <br>\n",
        "that depend on their momentum in a way determined by the atomic structure of <br> the crystal.\n",
        "\n",
        "However, there are other electronic phases of matter that are truly \"quantum\" <br>\n",
        "and cannot be described accurately with a classical analogy. <Br>\n",
        "In these scenarios, complicated structures in the electron states can give rise <br>\n",
        "to large electronic spin density or strong electron-electron coupling. <br>\n",
        "Because of these strong couplings between electrons, they are often hard to <br>\n",
        "probe experimentally.\n",
        "\n",
        "Luckily, electrons can interact with the nuclear spins of a material (by way of <br> the hyperfine-interaction).<br>\n",
        "If the electron-nuclear coupling becomes strong enough, then a non-neglible <br>\n",
        "two-step process can couple the nuclei with each other throughout the material. <br>\n",
        "That two-step process is when a nuclear spin couples to an electron and changes <br>\n",
        "its motion, and then that electron later \"scatters\" off another nuclear spin <br>\n",
        "elsewhere in the material.\n",
        "\n",
        "We represent this two-step scattering process by way of an effective spin-spin <br>\n",
        "coupling between a nuclei at position $r_j$ and $r_i$. **There are two datasets,** <br>\n",
        "**\"gauss\" and \"RKKY\", and thus you will have to generate TWO models and hand in** <br> **two models.**\n",
        "\n",
        "\n",
        "The first is a simple gaussian function (\"gauss\"):\n",
        "\n",
        "$T_1(i,j) = \\alpha \\exp{\\left[ \\left(\\frac{-|r_j - r_i|}{\\xi} \\right)^{2} \\right]}$\n",
        "\n",
        "And the second is the traditional Ruderman–Kittel–Kasuya–Yosida function <br> (\"RKKY\"):\n",
        "\n",
        "$T_2(i,j) = \\alpha x^{-4} \\left( x \\cos{x} - \\sin{x} \\right)$\n",
        "\n",
        "with $x = 2 \\frac{|r_j - r_i|}{\\xi}$\n",
        "\n",
        "\n",
        "For both function, $\\alpha$ is the coupling strength and $\\xi$ is the coupling length.\n",
        "\n",
        "Generally, $\\alpha$ and $\\xi$ will depend on the details of the nuclear-electron <br>\n",
        "coupling and the quantum state of the electrons, but here we will sample them <br>\n",
        "randomly to see if the spin-echo experiment can provide enough information to <br>\n",
        "accurately \"reverse engineer\" these values from a single $M(t)$ curve.\n",
        "\n",
        "Our simulations also include dissipation of the nuclear spins: due to couplings <br>\n",
        "with the environment the spin information can be \"lost\". <Br>\n",
        "This occurs at a time scale $T_\\textrm{decay} \\simeq \\Gamma^{-1/2}$, with $\\Gamma$ given by:\n",
        "\n",
        "$\\Gamma = 10^{-d}$\n",
        "\n",
        "Our goal is to develop two models, one for each function, that accurately <br> determine the above variables ($\\alpha$, $\\xi$, and $d$) from a single $M(t)$ curve. <br>\n",
        "Note that RKKY is a harder problem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Portion Begins Here"
      ],
      "metadata": {
        "id": "MZiwlWbfNRye"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyS96OqFeMk9"
      },
      "source": [
        "## Load and view the simulated data\n",
        "\n",
        "Three datafiles will be used for the training of both models. Each file has <br>\n",
        "6000 lines, representing 6000 simulated $M(t)$ curves for different choices of <br>\n",
        "the three material parameters:\n",
        "\n",
        "- \\<model name\\>_echos_model_r.txt  : Real part of the time-dependent <br> magnetization, $\\textrm{Re}(M(t))$.\n",
        "- \\<model name\\>_echos_model_i.txt  : Imaginary part of the time-dependent <br> magnetization, $\\textrm{Im}(M(t))$.\n",
        "- \\<model name\\>_mat_info_model.txt : The three material parameters <br> ($\\alpha$,$\\xi$,$d$) introduced above.\n",
        "\n",
        "Where \\<model name\\> is either \"gauss\" or \"RKKY\".\n",
        "\n",
        "We also load two other echo files, which give an additional 6000 $M(t)$ curves. <br>\n",
        "These will be used to judge the quality of your final models:\n",
        "\n",
        "- \\<model name\\>_echos_eval_r.txt\n",
        "- \\<model name\\>_echos_eval_i.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm3qvRtKeMk-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "print(\"Downloading files off google drive...\")\n",
        "\n",
        "f_prefix = \"gauss\"\n",
        "\n",
        "# data for model creation\n",
        "gauss_train_y = f_prefix+\"_mat_info_model.txt\"\n",
        "gauss_train_X_real = f_prefix+\"_echos_model_r.txt\" # real part of echos\n",
        "gauss_train_X_imaginary = f_prefix+\"_echos_model_i.txt\" # imaginary part of echos\n",
        "\n",
        "asdf = \"https://drive.google.com/uc?export=download&id=\"\n",
        "\n",
        "r = requests.get(\"https://drive.google.com/uc?export=download&id=1J8CcJVQRpzSwue1vuHV9uB0bngdDrKCY\",allow_redirects=True)\n",
        "open(gauss_train_y, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://drive.google.com/uc?export=download&id=1lBWcwF--1rrB8KCyCd0-5ZnPIjRrWkHg\",allow_redirects=True)\n",
        "open(gauss_train_X_real, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://drive.google.com/uc?export=download&id=1O7KKL-SW3vHePoRNk8YfLzX82wf2Z5ul\",allow_redirects=True)\n",
        "open(gauss_train_X_imaginary, \"wb\").write(r.content)\n",
        "\n",
        "# data for submission of final model\n",
        "gauss_test_X_real = f_prefix+\"_echos_eval_r.txt\" # real part of echos\n",
        "gauss_test_X_imaginary = f_prefix+\"_echos_eval_i.txt\" # imaginary part of echos\n",
        "\n",
        "r = requests.get(\"https://drive.google.com/uc?export=download&id=1prIrtO7XJs3PBe1MZiWUxK3VUkrChVvz\",allow_redirects=True)\n",
        "open(gauss_test_X_real, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://drive.google.com/uc?export=download&id=1vbKcuxe6z8cRGQdTqj_Q2u5Oow0D9hbU\",allow_redirects=True)\n",
        "open(gauss_test_X_imaginary, \"wb\").write(r.content)\n",
        "\n",
        "# now repeat, but for RKKY type function\n",
        "\n",
        "f_prefix = \"RKKY\"\n",
        "\n",
        "# data for model training\n",
        "rrky_train_y = f_prefix+\"_mat_info_model.txt\"\n",
        "rrky_train_X_real = f_prefix+\"_echos_model_r.txt\" # real part of echos\n",
        "rrky_train_X_imaginary = f_prefix+\"_echos_model_i.txt\" # imaginary part of echos\n",
        "r = requests.get(\"https://docs.google.com/uc?export=download&id=1lS9AJ3sUFI4cfM5jQj618x4shoaJMXVo\",allow_redirects=True)\n",
        "open(rrky_train_y, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://docs.google.com/uc?export=download&id=1J21bKy8FTjoaGzHVdLXlWAao2UiWO7ml\",allow_redirects=True)\n",
        "open(rrky_train_X_real, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://docs.google.com/uc?export=download&id=1nf3Y_FcJJEWXJbjwREAkgcnVz2tDA__I\",allow_redirects=True)\n",
        "open(rrky_train_X_imaginary, \"wb\").write(r.content)\n",
        "\n",
        "# data for submission of final model\n",
        "rrky_test_X_real = f_prefix+\"_echos_eval_r.txt\" # real part of echos\n",
        "rrky_test_X_imaginary = f_prefix+\"_echos_eval_i.txt\" # imaginary part of echos\n",
        "\n",
        "r = requests.get(\"https://docs.google.com/uc?export=download&id=1Q46o_RnYZFWEjMVVF5m1VBI9HCltspyY\",allow_redirects=True)\n",
        "open(rrky_test_X_real, \"wb\").write(r.content)\n",
        "r = requests.get(\"https://docs.google.com/uc?export=download&id=1-z2ADFrBlEhXN5Z_LHiRLA4Nds_9uvQq\",allow_redirects=True)\n",
        "open(rrky_test_X_imaginary, \"wb\").write(r.content)\n",
        "\n",
        "\n",
        "print(\"Done with file downloads\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gauss_train_X_real = np.loadtxt(gauss_train_X_real, comments=\"#\", delimiter=None, unpack=False)\n",
        "gauss_train_X_imaginary = np.loadtxt(gauss_train_X_imaginary, comments=\"#\", delimiter=None, unpack=False)\n",
        "gauss_train_y = np.loadtxt(gauss_train_y, comments=\"#\", delimiter=None, unpack=False)\n",
        "\n",
        "gauss_test_X_real = np.loadtxt(gauss_test_X_real, comments=\"#\", delimiter=None, unpack=False)\n",
        "gauss_test_X_imaginary = np.loadtxt(gauss_test_X_imaginary, comments=\"#\", delimiter=None, unpack=False)\n",
        "\n",
        "rkky_train_X_real = np.loadtxt(rrky_train_X_real, comments=\"#\", delimiter=None, unpack=False)\n",
        "rkky_train_X_imaginary = np.loadtxt(rrky_train_X_imaginary, comments=\"#\", delimiter=None, unpack=False)\n",
        "rkky_train_y = np.loadtxt(rrky_train_y, comments=\"#\", delimiter=None, unpack=False)\n",
        "\n",
        "rkky_test_X_real = np.loadtxt(rrky_test_X_real, comments=\"#\", delimiter=None, unpack=False)\n",
        "rkky_test_X_imaginary = np.loadtxt(rrky_test_X_imaginary, comments=\"#\", delimiter=None, unpack=False)"
      ],
      "metadata": {
        "id": "xogFKL42TUwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTANT NOTE IF YOU WANT TO SAVE A LOT OF TIME WHILE TESTING THINGS\n",
        "\n",
        "The full time series contain a lot of information that might not actually be <br>\n",
        "useful. Here the key region of interest is around 200-400 so you could cut <br>\n",
        "down the length of the time series to that window. It may slightly worsen <br>\n",
        "final model performance but can save a ton of time.<br>\n",
        "e.g. `gauss_train_X_imaginary = gauss_train_X_imaginary[:,200:400]`"
      ],
      "metadata": {
        "id": "8HLRFN3Zf3NR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot((gauss_train_X_imaginary[1:500,:]).T,color='orange', alpha=0.05)\n",
        "plt.plot((gauss_train_X_real[1:500,:]).T,color='blue', alpha=0.05)\n",
        "plt.xlabel(\"$t$\")\n",
        "plt.ylabel(\"$M$\")\n",
        "plt.legend()\n",
        "plt.title(\"Training set with a full time axis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CYo0ZFV0dD49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rescale data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "gauss_X_sc_real = StandardScaler()\n",
        "gauss_train_X_real = gauss_X_sc_real.fit_transform(gauss_train_X_real)\n",
        "gauss_test_X_real = gauss_X_sc_real.transform(gauss_test_X_real)\n",
        "gauss_X_sc_imaginary = StandardScaler()\n",
        "gauss_train_X_imaginary = gauss_X_sc_imaginary.fit_transform(gauss_train_X_imaginary)\n",
        "gauss_test_X_real = gauss_X_sc_imaginary.transform(gauss_test_X_imaginary)\n",
        "gauss_y_sc = StandardScaler()\n",
        "gauss_train_y = gauss_y_sc.fit_transform(gauss_train_y)\n",
        "\n",
        "rkky_X_sc_real = StandardScaler()\n",
        "rkky_train_X_real = rkky_X_sc_real.fit_transform(rkky_train_X_real)\n",
        "rkky_test_X_real = rkky_X_sc_real.transform(rkky_test_X_real)\n",
        "rkky_X_sc_imaginary = StandardScaler()\n",
        "rkky_train_X_imaginary = rkky_X_sc_imaginary.fit_transform(rkky_train_X_imaginary)\n",
        "rkky_test_X_real = rkky_X_sc_imaginary.transform(rkky_test_X_imaginary)\n",
        "rkky_y_sc = StandardScaler()\n",
        "rkky_train_y = rkky_y_sc.fit_transform(rkky_train_y)\n",
        "\n",
        "# partition data into a training and testing set using a random partition\n",
        "from sklearn.model_selection import train_test_split\n",
        "gauss_train_X_real, gauss_valid_X_real = train_test_split(gauss_train_X_real, test_size=0.1, random_state=42)\n",
        "gauss_train_X_imaginary, gauss_valid_X_imaginary = train_test_split(gauss_train_X_imaginary, test_size=0.1, random_state=42)\n",
        "gauss_train_y, gauss_valid_y = train_test_split(gauss_train_y, test_size=0.1, random_state=42)\n",
        "rkky_train_X_real, rkky_valid_X_real = train_test_split(rkky_train_X_real, test_size=0.1, random_state=42)\n",
        "rkky_train_X_imaginary, rkky_valid_X_imaginary = train_test_split(rkky_train_X_imaginary, test_size=0.1, random_state=42)\n",
        "rkky_train_y, rkky_valid_y = train_test_split(rkky_train_y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "92Qjtn9oSgeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoChannelTimeSeries(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = np.stack(X, axis=2)\n",
        "        self.X = torch.from_numpy(self.X.copy()).float()\n",
        "        if y is not None:\n",
        "            self.y = torch.from_numpy(y.copy()).float()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.X[idx]\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_data = TwoChannelTimeSeries([gauss_train_X_real, gauss_train_X_imaginary], gauss_train_y)\n",
        "valid_data = TwoChannelTimeSeries([gauss_valid_X_real, gauss_valid_X_imaginary], gauss_valid_y)\n",
        "test_data = TwoChannelTimeSeries([gauss_test_X_real, gauss_test_X_imaginary], None)\n",
        "\n",
        "gauss_train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "gauss_valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
        "gauss_test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "train_data = TwoChannelTimeSeries([rkky_train_X_real, rkky_train_X_imaginary], rkky_train_y)\n",
        "valid_data = TwoChannelTimeSeries([rkky_valid_X_real, rkky_valid_X_imaginary], rkky_valid_y)\n",
        "test_data = TwoChannelTimeSeries([rkky_test_X_real, rkky_test_X_imaginary], None)\n",
        "\n",
        "rkky_train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "rkky_valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
        "rkky_test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "PudOUbQWQo5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric=None, scheduler=None, device='cpu'):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X, y in train_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y = y\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, y)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                epoch_metric += metric(outputs, y)\n",
        "            else:\n",
        "                epoch_metric += 0.0\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val, y_val in val_loader:\n",
        "                X_val = X_val.to(device)\n",
        "                y_val = y_val.to(device)\n",
        "                y_val = y_val\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, y_val).item()  # Compute loss\n",
        "                if metric is not None:\n",
        "                    val_metric += metric(outputs_val, y_val)\n",
        "                else:\n",
        "                    val_metric += 0.0\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    return history, model\n",
        "\n",
        "\n",
        "def test_model(model, data_loader, criterion, metric=None, device='cpu'):\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_loss = 0.0  # Initialize the total loss and metric values\n",
        "    total_metric = 0.0\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking\n",
        "        for batch in data_loader:\n",
        "            X, y = batch\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            # Pass the data to the model and make predictions\n",
        "            outputs = model(X)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            # Add the loss and metric for the batch to the total values\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if metric is not None:\n",
        "                total_metric += metric(outputs, y)\n",
        "            else:\n",
        "                total_metric += 0.0\n",
        "\n",
        "    # Average loss and metric for the entire dataset\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_metric = total_metric / len(data_loader)\n",
        "\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Test Metric: {avg_metric:.4f}')\n",
        "\n",
        "    return avg_loss, avg_metric"
      ],
      "metadata": {
        "id": "Bze1XMHiXeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bb9p8ytmXhuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RliStr5CeMlC"
      },
      "source": [
        "## Example solution: a simple neural net (NN)\n",
        "- Our input nodes are the vector $[\\textrm{Re}(M(t)), \\textrm{Im}(M(t))]$, which is a few hundred elements.\n",
        "- Our output nodes are the three material parameters.\n",
        "- We will use a standard NN predict the material properties from $M(t)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFdUzF8yeMlC"
      },
      "outputs": [],
      "source": [
        "# first we build the model\n",
        "\n",
        "N = np.shape(next(iter(gauss_train_loader))[0])[1] # number of input values from M(t) curve\n",
        "\n",
        "# define the net\n",
        "simplenn = nn.Sequential()\n",
        "# Let's try N -> 100 -> 40 -> 3, e.g. 2 hidden layers\n",
        "simplenn.append(nn.Flatten())\n",
        "simplenn.append(nn.Linear(N*2, 100))\n",
        "simplenn.append(nn.ReLU())\n",
        "simplenn.append(nn.Linear(100, 40))\n",
        "simplenn.append(nn.ReLU())\n",
        "simplenn.append(nn.Linear(40, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csDDTh1TeMlC"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(simplenn.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()\n",
        "# now train it\n",
        "history, simplenn = train_and_validate(gauss_train_loader, gauss_valid_loader, simplenn, optimizer, criterion, num_epochs=200, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNmHuEm0eMlD"
      },
      "outputs": [],
      "source": [
        "# check results on test set\n",
        "results = test_model(simplenn, gauss_valid_loader, criterion, device=device)\n",
        "print(\"test loss:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simplenn.to('cpu')\n",
        "simplenn.eval()\n",
        "predictions = [simplenn(x[0]).detach().numpy() for x in gauss_valid_loader]\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "predictions = gauss_y_sc.inverse_transform(predictions)\n",
        "true = gauss_y_sc.inverse_transform(gauss_valid_loader.dataset.y.numpy())"
      ],
      "metadata": {
        "id": "Qe3FcEcWZaM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model performance visualization\n",
        "\n",
        "The quantities you are trying to predict and the associated predictions are <br>\n",
        "shown below. They are `alpha`, `xi`, and `d`. Below true and predicted values <br>\n",
        "are compared using a correlation plot."
      ],
      "metadata": {
        "id": "rdwjtKVEg8Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(predictions[:,0],true[:,0]);\n",
        "plt.plot([-100,100],[-100, 100],\"--k\")\n",
        "plt.xlabel(\"True alpha\");\n",
        "plt.ylabel(\"Predicted alpha\");\n",
        "plt.axis([-2, 24, -2, 24])\n",
        "plt.title(\"Correlation strength\")\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(predictions[:,1],true[:,1]);\n",
        "plt.plot([-100, 100],[-100, 100],\"--k\")\n",
        "plt.xlabel(\"True xi\");\n",
        "plt.ylabel(\"Predicted xi\");\n",
        "plt.axis([0, 70, 0, 70])\n",
        "plt.title(\"Correlation length\")\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(predictions[:,2],true[:,2]);\n",
        "plt.plot([-100, 100],[-100, 100],\"--k\")\n",
        "plt.xlabel(\"True d\");\n",
        "plt.ylabel(\"Predicted d\");\n",
        "plt.axis([5, 12, 5, 12])\n",
        "plt.title(\"Dissipation strength\")"
      ],
      "metadata": {
        "id": "lvXkonAxZSxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkipX19ReMlD"
      },
      "source": [
        "## Submission format\n",
        "\n",
        "__We ask you to submit two models: one for guass and one for rkky__\n",
        "\n",
        "We ask you to make your predictions on the test sets. You don't have the true <br>\n",
        "labels for the test sets meaning you are limited only to what you know about <br>\n",
        "train sets (and validation subsets) to build the best models possible.\n",
        "\n",
        "Use your models to predict the three spin-interaction variables from the  <br>\n",
        "echos, and submit your results for **each model** in a tab delimited .txt  <br>\n",
        "file of dimensions 6000 x 3 matching the \"\\<model_type\\>\\_mat_info_model.txt\" format.\n",
        "\n",
        "That is, the columns should be:\n",
        "\n",
        "| $\\alpha$ | $\\xi$ | $d$ |\n",
        "      \n",
        "and there should be 6000 rows.\n",
        "\n",
        "Name this file \"\\<model_type\\>_mat_info_eval.txt\"\n",
        "\n",
        "The quality of the model will be judged by the minimization of normalized <br> mean-square error:\n",
        "\n",
        "\n",
        "$\\textrm{Err} = \\sum_{v=1}^{3} \\sum_{i=i}^{6000} \\left( \\tilde{v}^i_\\textrm{model} - \\tilde{v}^i_\\textrm{true} \\right)^2 $\n",
        "\n",
        "where $v^i$ is one of the three spin-interaction variables for echo number $i$, <br>\n",
        "and the tilde represents normalization of each variable (using the <br> StandardScaler() object used above).\n",
        "\n",
        "\n",
        "Your submission should include: <br>\n",
        "- Your ipython notebook (`.ipynb`),<br>\n",
        "- A PDF copy of your notebook together with a description of what you have done,<br>\n",
        "- Your model's evaluation of the Gaussian data (\"gauss_mat_info_eval.txt\"), <br>\n",
        "- Your model's evaluation of the RKKY data (\"RKKY_mat_info_eval.txt\").\n",
        "\n",
        "**NOTE: If your final model prediction files aren't named like** <br>\n",
        "**\"gauss_mat_info_eval.txt\" and \"RKKY_mat_info_eval.txt\" your results cannot be**<br>\n",
        "**counted for hackathon rankings.**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}