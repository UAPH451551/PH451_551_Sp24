{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UAPH451551/PH451_551_Sp24/blob/main/Exercises/08A_autoencoders_and_gans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0234KzN5W_Yr"
      },
      "source": [
        "# Hands On #8A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u409K-vLW_Yt"
      },
      "source": [
        "**Chapter 17 – Autoencoders and GANs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_5rT9hCW_Yu"
      },
      "source": [
        "File name convention: For group 42 and memebers Richard Stallman and Linus <br>\n",
        "Torvalds it would be <br>\n",
        "\"08_group42_Stallman_Torvalds.pdf\".\n",
        "\n",
        "Submission via blackboard (UA).\n",
        "\n",
        "Feel free to answer free text questions in text cells using markdown and <br>\n",
        "possibly $\\LaTeX{}$ if you want to.\n",
        "\n",
        "**You don't have to understand every line of code here and it is not intended <br>\n",
        "for you to try to understand every line of code.   <br>\n",
        "Big blocks of code are usually meant to just be clicked through.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nBVIiFCW_Yv"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z7QD-rNW_Yv"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "VnMawNG3M98X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMItxgFSW_Yw"
      },
      "source": [
        "A couple utility functions to plot grayscale 28x28 image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm5m1yefW_Yw"
      },
      "outputs": [],
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(np.moveaxis(image, 0, 2), cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R29YO-K-W_Yw"
      },
      "source": [
        "# Simple linear Autoencoder (PCA)\n",
        "\n",
        "Autoencoders are form of **unsupervised learning** algorithm that attempt to encode <br>\n",
        "or **transform** an input into some sort of (typically **lower-dimensional**) space <br>\n",
        "where it has different values and then decode the encoded data back to its <br>\n",
        "**original state**. A consequence of this approach is that your model learns the <br>\n",
        "**characteristic behavior** of your data set. Once trained, autoencoders can do <br>\n",
        "everything from **detect anomalies** and outliers in unseen data to **adding or** even <br>\n",
        "**removing noise** from new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cLWKPG6W_Yx"
      },
      "source": [
        "Build 3D dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzyx9W8AW_Yx"
      },
      "outputs": [],
      "source": [
        "np.random.seed(4)\n",
        "\n",
        "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
        "    \"\"\"create some 3d data with noise\"\"\"\n",
        "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "    data = np.empty((m, 3))\n",
        "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
        "    return data\n",
        "\n",
        "X_train = generate_3d_data(1000)\n",
        "X_train = X_train - X_train.mean(axis=0, keepdims=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OErD4LRobu0Z"
      },
      "outputs": [],
      "source": [
        "class AutoencoderDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = torch.from_numpy(X.copy()).float()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "train_data = AutoencoderDataset(X_train)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfM-z47EW_Yx"
      },
      "outputs": [],
      "source": [
        "ax = plt.axes(projection=\"3d\")\n",
        "ax.scatter3D(X_train[:,0], X_train[:,1], X_train[:,2], c=X_train[:,2], cmap=\"viridis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbRI2sf0W_Yx"
      },
      "source": [
        "Let's try to \"compress\" the data using an autoencoder.\n",
        "\n",
        "As a sidenote: Compression is tightly linked to intelligence and there are even arguments\n",
        "that compression might be all there is to intelligence.   \n",
        "If you are interested in this topic you can read about the [Hutter prize](http://prize.hutter1.net/hrules.htm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoxoebi3W_Yx"
      },
      "source": [
        "Now let's build the Autoencoder..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG0df7Z3W_Yy"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# encoder: from 3 to 2 dimensions\n",
        "encoder = nn.Sequential(nn.Linear(3, 2))\n",
        "# decoder: from 2 to 3 dimensions\n",
        "decoder = nn.Sequential(nn.Linear(2, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqjQM9F1W_Yy"
      },
      "outputs": [],
      "source": [
        "print(encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d_T0vuQW_Yy"
      },
      "outputs": [],
      "source": [
        "print(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bahAURuP2lV0"
      },
      "outputs": [],
      "source": [
        "def ae_train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric=None, scheduler=None, device='cpu'):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X = next(iter(train_loader))\n",
        "        X = X.to(device)\n",
        "        try:\n",
        "            loss = criterion(model(X), X)\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), X)\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X in train_loader:\n",
        "            X = X.to(device)\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, X)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if metric is not None:\n",
        "                epoch_metric += metric(outputs, X)\n",
        "            else:\n",
        "                epoch_metric += 0.0\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val in val_loader:\n",
        "                X_val = X_val.to(device)\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, X_val).item()  # Compute loss\n",
        "                if metric is not None:\n",
        "                    val_metric += metric(outputs_val, X_val)\n",
        "                else:\n",
        "                    val_metric += 0.0\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    return history, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyBwLFzh2uo3"
      },
      "outputs": [],
      "source": [
        "def ae_test_model(model, data_loader, criterion, metric=None, device='cpu'):\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_loss = 0.0  # Initialize the total loss and metric values\n",
        "    total_metric = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X = next(iter(data_loader))\n",
        "        X = X.to(device)\n",
        "        try:\n",
        "            loss = criterion(model(X), X)\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), X)\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking\n",
        "        for batch in data_loader:\n",
        "            X, y = batch\n",
        "            X = X.to(device)\n",
        "\n",
        "            # Pass the data to the model and make predictions\n",
        "            outputs = model(X)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, X)\n",
        "\n",
        "            # Add the loss and metric for the batch to the total values\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if metric is not None:\n",
        "                total_metric += metric(outputs, X)\n",
        "            else:\n",
        "                total_metric += 0.0\n",
        "\n",
        "    # Average loss and metric for the entire dataset\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_metric = total_metric / len(data_loader)\n",
        "\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Test Metric: {avg_metric:.4f}')\n",
        "\n",
        "    return avg_loss, avg_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH-fJHoLW_Yy"
      },
      "source": [
        "## Task 1:\n",
        "If you don't understand autoencoders, we strongly recommend reading the parts <br>\n",
        "in the book (Chapter 17) first.\n",
        "\n",
        "a) Build an autoencoder model with the two subcomponents: the encoder and the <br>\n",
        "decoder. All you have to do is to \"stack\" the encoder and decoder, `encoder,` <br> `decoder` in a `nn.Sequential`.  <br>\n",
        "b) Train the model using `ae_train_and_validate()` with `MSELoss` <br>\n",
        "SGD optimizer with lr=0.01, train_loader (20 epochs). Be sure to just pass\n",
        "<br>\n",
        "train_loader twice as there's no valid_loader for this section.<br>\n",
        "c) Encode the dataset using only the trained encoder. The `encoder` will be <br>\n",
        "mutated by the autoencoder training, so you can just use it to do this step <br>\n",
        "because it is already trained. Call the output `codings` for the plotting code <br>\n",
        "below.<br>\n",
        "d) Look at the plot of the encodings and explain the purpose of this <br> encoder. <br>\n",
        "e) Decode the encodings again and plot them in 3D using the same code as above <br>\n",
        "when we plot `X_train`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsnymzLuLvm2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRvpXuFobkAs"
      },
      "outputs": [],
      "source": [
        "# autoencoder = nn.Sequential(...\n",
        "# )\n",
        "# optimizer = ...\n",
        "# criterion = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F2BOiGBbmeE"
      },
      "outputs": [],
      "source": [
        "# history, autoencoder = ae_train_and_validate(train_loader,..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWozDSPzeJBE"
      },
      "outputs": [],
      "source": [
        "# codings = encoder(torch.from_numpy(np.asarray(X_train, np.float32))).to('cpu').detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfzdwhoRW_Yz"
      },
      "outputs": [],
      "source": [
        "# fig = plt.figure(figsize=(4,3))\n",
        "# plt.plot(codings[:,0], codings[:, 1], \"b.\")\n",
        "# plt.xlabel(\"$z_1$\", fontsize=18)\n",
        "# plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoded_data = decoder(torch.from_numpy(codings).float()).to('cpu').detach().numpy()"
      ],
      "metadata": {
        "id": "ydeZY8PFLQZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ax = plt.axes(projection=\"3d\")\n",
        "# ax.scatter3D(..."
      ],
      "metadata": {
        "id": "O6BdxLS6K-4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1d) answer:"
      ],
      "metadata": {
        "id": "x5WLXNP_Nane"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1e) answer:"
      ],
      "metadata": {
        "id": "m0SvehplNeZk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L33GBuxILvm4"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTyuFXyEW_Yz"
      },
      "source": [
        "# Autoencoder for MNIST\n",
        "Let's use the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Zf5LOgW_Yz"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blPGkpWjfJfh"
      },
      "outputs": [],
      "source": [
        "class AutoencoderDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = torch.from_numpy(X.copy()).float()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "train_data = AutoencoderDataset(X_train)\n",
        "valid_data = AutoencoderDataset(X_valid)\n",
        "test_data = AutoencoderDataset(X_test)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9SZ-YQoW_Yz"
      },
      "source": [
        "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6TqlRqWW_Yz"
      },
      "outputs": [],
      "source": [
        "encoder2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 30),\n",
        "    nn.SELU(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzHB9kLjW_Y0"
      },
      "source": [
        "## Task 2:\n",
        "a) Above the code for the encoder is given. Build the corresponding decoder <br>\n",
        "(`decoder2`). The last two layers of the decoder will have to be <br>\n",
        "`nn.Sigmoid()` and `nn.Unflatten(1,(28, 28))`. Just like in task 1, build\n",
        "<br>\n",
        "`autoencoder2` from `encoder2` and `decoder2`.<br>\n",
        "b) Train the model using `ae_train_and_validate()` with binary cross <br>\n",
        "entropy, SGD optimizer with lr=0.1, train_loader (30 epochs) and <br> valid_loader.<br>\n",
        "c) Using the function `show_reconstructions` below, look at the reconstructions <br>\n",
        "and comment on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bde7eOP4W_Y0"
      },
      "outputs": [],
      "source": [
        "def show_reconstructions(model, dataloader=valid_loader, n_images=5, extra_layer=None):\n",
        "    model.eval()\n",
        "\n",
        "    for images in dataloader:\n",
        "        break\n",
        "\n",
        "    if images.shape[1] != 1:\n",
        "        images = images.unsqueeze(1)\n",
        "\n",
        "    images = images.to(next(model.parameters()).device)\n",
        "    if extra_layer is not None:\n",
        "        extra_layer.to(next(model.parameters()).device)\n",
        "        images = extra_layer(images)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        reconstructions = model(images[:n_images])\n",
        "\n",
        "    if isinstance(reconstructions, tuple):\n",
        "        reconstructions = reconstructions[0]  # Assume the first element is what we need\n",
        "    reconstructions = reconstructions.to('cpu').detach().numpy()\n",
        "\n",
        "    if reconstructions.shape[1] != 1:\n",
        "        reconstructions = reconstructions[:,np.newaxis,...]\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plot_image(images.to('cpu').detach().numpy()[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plot_image(reconstructions[image_index])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWHr9I8qW_Y0"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder2 = nn.Sequential(\n",
        "    nn.Linear(30, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 784),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Unflatten(1,(28, 28))\n",
        ")\n",
        "autoencoder2 = nn.Sequential(\n",
        "    encoder2,\n",
        "    decoder2\n",
        ")\n",
        "optimizer = torch.optim.SGD(autoencoder2.parameters(), lr=0.1)\n",
        "criterion = nn.BCELoss()\n",
        "history, autoencoder2 = ae_train_and_validate(train_loader, valid_loader, autoencoder2, optimizer, criterion, 30)"
      ],
      "metadata": {
        "id": "en77-3Ov5Qpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder2 = nn.Sequential(...\n",
        "#autoencoder2 = nn.Sequential(...\n",
        "#optimizer = ...\n",
        "#criterion = ...\n",
        "#history, autoencoder2 = ae_train_and_validate(..."
      ],
      "metadata": {
        "id": "ducKPCqpI2BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2c) answer:"
      ],
      "metadata": {
        "id": "VQ22DVN4Iqlr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAOmhtneW_Y0"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE3vvgMqW_Y0"
      },
      "source": [
        "### \"Looking\" at the encoding\n",
        "Here we wil in some sense \"look\" at the encoding. <br>\n",
        "We will use TSNE to transform the encoding to 2D and then plot in a 2D plane.<br>\n",
        "\n",
        "No questions to anwer here, just look at the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9_BTvA5rBrF"
      },
      "outputs": [],
      "source": [
        "!pip install bhtsne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzZzCis_W_Y0"
      },
      "outputs": [],
      "source": [
        "#Textbook uses from sklearn.manifold import TSNE but that has known bugs w/ colab on mac\n",
        "from bhtsne import tsne\n",
        "\n",
        "X_valid_compressed = [encoder2(v.to(device)).to('cpu').detach().numpy() for v in valid_loader]\n",
        "X_valid_compressed = np.concatenate(X_valid_compressed, dtype=np.float64)\n",
        "X_valid_2D = tsne(X_valid_compressed)\n",
        "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdI_QtHUW_Y1"
      },
      "outputs": [],
      "source": [
        "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
        "plt.figure(figsize=(10, 8))\n",
        "cmap = plt.cm.tab10\n",
        "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid[:-8], s=10, cmap=cmap)\n",
        "image_positions = np.array([[1., 1.]])\n",
        "for index, position in enumerate(X_valid_2D):\n",
        "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
        "    if np.min(dist) > 0.02: # if far enough from other images\n",
        "        image_positions = np.r_[image_positions, [position]]\n",
        "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n",
        "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
        "        plt.gca().add_artist(imagebox)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttNQcv9rJSuY"
      },
      "source": [
        "##GPU Time:\n",
        "**If you haven't enabled GPU in your colab notebook, now is the time to do so.** <br>\n",
        "Only one group member should be working with GPU at a time as you will each <br>\n",
        "have a limit on how often and for how long colab will allow you to use gpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2hW3OW2cBlq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwgpuuBrW_Y1"
      },
      "source": [
        "## Using Convolutional Layers Instead of Dense Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGqyepHW_Y1"
      },
      "source": [
        "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdO-hSevW_Y1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "conv_encoder = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "    nn.SELU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "    nn.SELU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "    nn.SELU(),\n",
        "    nn.MaxPool2d(kernel_size=2)\n",
        ")\n",
        "\n",
        "conv_decoder = nn.Sequential(\n",
        "    # Start reversing the process, assuming the final encoder output is 3x3x64 for a 28x28 input\n",
        "    nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=0),  # Upscale to 7x7\n",
        "    nn.SELU(),\n",
        "    # Upscale from 7x7 to 14x14\n",
        "    nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "    nn.SELU(),\n",
        "    # Final upscale from 14x14 to 28x28\n",
        "    nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvPRQKbPU6k0"
      },
      "source": [
        "### Reloading Dataset with Proper Shape for Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAYsWSRhW_Y2"
      },
      "source": [
        "Above is a visual representation of the encoder. Alas visualkeras does not <br>\n",
        "support `ConvTranspose2d` so we cannot plot the decoder here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6QHgGMtVAi1"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "\n",
        "#Notice that pytorch convolutional layers expect the 1-axis to be the channels\n",
        "#dimension whereas generally linear layers will act on the last axis.\n",
        "\n",
        "X_train = X_train[:, np.newaxis, ...]\n",
        "X_valid = X_valid[:, np.newaxis, ...]\n",
        "X_test = X_test[:, np.newaxis, ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23aI-iNVVAi7"
      },
      "outputs": [],
      "source": [
        "class AutoencoderDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = torch.from_numpy(X.copy()).float()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "train_data = AutoencoderDataset(X_train)\n",
        "valid_data = AutoencoderDataset(X_valid)\n",
        "test_data = AutoencoderDataset(X_test)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "conv_train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "conv_valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "conv_test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lekkehZEW_Y2"
      },
      "source": [
        "### Task 3:\n",
        "a) Build an autoencoder model with the two subcomponents: the convolutional <br>\n",
        "encoder and the convolutional decoder.<br>\n",
        "b) Train the model using `ae_train_and_validate()` with binary cross <br>\n",
        "entropy, SGD optimizer with lr=0.1, conv_train_loader (30 epochs) and <br> conv_valid_loader.<br>\n",
        "c) Is the CNN autoencoder better than dense layer's autoencoders? Why?<br>\n",
        "d) What is the shape/size of the input and what is the shape/size of the<br>\n",
        "encoding? Compare to the autoencoder above. (This is similar to task 2c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CwNQtjPW_Y2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auSbNXYlZ-Uv"
      },
      "outputs": [],
      "source": [
        "#conv_ae = nn.Sequential(...\n",
        "#optimizer = ...\n",
        "#criterion ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrwtEh1uVWJX"
      },
      "outputs": [],
      "source": [
        "#history, conv_ae = ae_train_and_validate("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPY99cNJW_Y2"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54gnrKVcIsV4"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc1u-p30IsV4"
      },
      "source": [
        "Task 3c) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3d) answer:"
      ],
      "metadata": {
        "id": "UgHdGP2mIyiY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbDqbAI6IsV5"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSsD3rUzW_Y2"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(conv_ae, conv_test_loader)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sod574_wW_Y2"
      },
      "source": [
        "# Denoising Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HeIljQuW_Y2"
      },
      "source": [
        "Below we have a similar autoencoder as before, but with an extra <br> `GaussianNoise` layer directly after the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-RiEdonRsLB"
      },
      "outputs": [],
      "source": [
        "#Source: whywww and YannDubs1 from pytorch forums\n",
        "#https://discuss.pytorch.org/t/writing-a-simple-gaussian-noise-layer-in-pytorch/4694/8\n",
        "class GaussianNoise(nn.Module):\n",
        "    \"\"\"Gaussian noise regularizer.\n",
        "\n",
        "    Args:\n",
        "        sigma (float, optional): relative standard deviation used to generate the\n",
        "            noise. Relative means that it will be multiplied by the magnitude of\n",
        "            the value your are adding the noise to. This means that sigma can be\n",
        "            the same regardless of the scale of the vector.\n",
        "        is_relative_detach (bool, optional): whether to detach the variable before\n",
        "            computing the scale of the noise. If `False` then the scale of the noise\n",
        "            won't be seen as a constant but something to optimize: this will bias the\n",
        "            network to generate vectors with smaller values.\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
        "        super().__init__()\n",
        "        self.sigma = sigma\n",
        "        self.is_relative_detach = is_relative_detach\n",
        "        self.register_buffer('noise', torch.tensor(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training and self.sigma != 0:\n",
        "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
        "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
        "            x = x + sampled_noise\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRcb1PS8W_Y2"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "denoising_encoder = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    GaussianNoise(0.2),\n",
        "    nn.Linear(784, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 30),\n",
        "    nn.SELU()\n",
        ")\n",
        "\n",
        "denoising_decoder = nn.Sequential(\n",
        "    nn.Linear(30, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 784),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Unflatten(1, (28, 28))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXbFNHO5W_Y3"
      },
      "source": [
        "### Task 4:\n",
        "a) Build an autoencoder model with the two subcomponents: the encoder and the <br>\n",
        "decoder.<br>\n",
        "b) Train the model using `ae_train_and_validate()` with binary cross <br>\n",
        "entropy, SGD optimizer with lr=1.0, train_loader (30 epochs) and <br> valid_loader.<br>\n",
        "c) Explain why adding Gaussian noise to the input would help the autoencoder to <br>\n",
        "learn.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfvpHN08W_Y3"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaJu8WFLW_Y3"
      },
      "outputs": [],
      "source": [
        "#denoising_ae = nn.Sequential(...\n",
        "#optimizer = ...\n",
        "#criterion = ...\n",
        "#history, denoising_ae = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYshb9abW_Y3"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X6BRXyraUnc"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUcpzlzCaV_B"
      },
      "source": [
        "Task 4c) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPI-DZQkaQDn"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9zZ51PUW_Y4"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = GaussianNoise(0.2)\n",
        "show_reconstructions(denoising_ae, extra_layer=noise)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq2L96DpW_Y4"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(denoising_ae)   # denoising autoencoder applied to \"sharp\" images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KeFteGGW_Y4"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(autoencoder2)   # original autoencoder without Gaussian noise\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXnhcxTxW_Y4"
      },
      "source": [
        "# Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkmW9Zb9W_Y4"
      },
      "source": [
        "### Task 5:\n",
        "Below you see the implementation of a variational autoencoder.   \n",
        "\n",
        "a) Explain how a variational autoencoder works. What are the differences to a<br>\n",
        "normal autoencoder? <br>\n",
        "b) Explain how you would \"generate\" new data with a variational autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06-8_OFW_Y4"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TcxIddFW_Y4"
      },
      "source": [
        "Task 5a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvfmTHoCW_Y4"
      },
      "source": [
        "Task 5b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aU2NupCW_Y5"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmlB4T9KW_Y7"
      },
      "outputs": [],
      "source": [
        "class Sampling(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4d2ad4RW_Y7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "class VariationalEncoder(nn.Module):\n",
        "    def __init__(self, codings_size):\n",
        "        super(VariationalEncoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 150)\n",
        "        self.linear2 = nn.Linear(150, 100)\n",
        "        self.codings_mean = nn.Linear(100, codings_size)\n",
        "        self.codings_log_var = nn.Linear(100, codings_size)\n",
        "        self.sampling = Sampling()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.selu(self.linear1(x.view(-1, 28*28)))\n",
        "        x = F.selu(self.linear2(x))\n",
        "        codings_mean = self.codings_mean(x)\n",
        "        codings_log_var = self.codings_log_var(x)\n",
        "        codings = self.sampling([codings_mean, codings_log_var])\n",
        "        return codings_mean, codings_log_var, codings\n",
        "\n",
        "class VariationalDecoder(nn.Module):\n",
        "    def __init__(self, codings_size):\n",
        "        super(VariationalDecoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(codings_size, 100)\n",
        "        self.linear2 = nn.Linear(100, 150)\n",
        "        self.linear3 = nn.Linear(150, 28*28)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.selu(self.linear1(x))\n",
        "        x = F.selu(self.linear2(x))\n",
        "        x = torch.sigmoid(self.linear3(x))\n",
        "        return x.view(-1, 28, 28)\n",
        "\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, codings_size):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(codings_size)\n",
        "        self.decoder = VariationalDecoder(codings_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        codings_mean, codings_log_var, codings = self.encoder(x)\n",
        "        reconstructions = self.decoder(codings)\n",
        "        return reconstructions, codings_mean, codings_log_var"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    # Binary Cross Entropy\n",
        "    BCE = torch.nn.functional.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='mean')\n",
        "    # KL Divergence\n",
        "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()) / 784\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "kQ3e3fKwLG-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_train_and_validate(train_loader, val_loader, model, optimizer, num_epochs, metric=None, scheduler=None, device='cpu'):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        for X in train_loader:\n",
        "            X = X.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(X)\n",
        "            loss = vae_loss(recon_batch, X, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_val in val_loader:\n",
        "                X_val = X_val.to(device)\n",
        "                recon_batch, mu, logvar = model(X_val)\n",
        "                val_loss += vae_loss(recon_batch, X_val, mu, logvar).item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "udv64pbBLPb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codings_size = 10\n",
        "variational_ae = VariationalAutoencoder(codings_size)\n",
        "optimizer = torch.optim.SGD(variational_ae.parameters(), lr=1)\n",
        "history, variational_ae = vae_train_and_validate(train_loader, valid_loader, variational_ae, optimizer, num_epochs=30, device=device)"
      ],
      "metadata": {
        "id": "8h_wJ_BaLQiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8D8-xNXW_Y7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "show_reconstructions(variational_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMCGS8ZJW_Y8"
      },
      "source": [
        "## Generate Fashion Images\n",
        "Now that we have a variational autoencoder, we can use it to generate fashion <br>\n",
        "images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFioQhixW_Y8"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngYgZ3xKW_Y8"
      },
      "source": [
        "Let's generate a few random codings, decode them and plot the resulting images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-FUu8b4W_Y8"
      },
      "source": [
        "### Task 6:\n",
        "a) Take the encoding of the first image `X_train[0:1]` and add multiples (-10 <br>\n",
        "to 10) of `np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])`. Decode and plot using <br>\n",
        "`plot_multiple_images()`. <br>\n",
        "**Hint:** The output of `variational_encoder` is  <br>`[codings_mean, codings_log_var, codings]` and you only need the codings, not <br>\n",
        "the mean and var. <br>\n",
        "b) Generate few (e.g. 12) random codings using for example [torch.randn](https://pytorch.org/docs/stable/generated/torch.randn.html). <br>\n",
        "Decode them and plot the resulting images using `plot_multiple_images(images, 4)`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx_KjiaBW_Y8"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_codings = variational_ae.encoder(...\n",
        "\n",
        "# coding_root = torch.tensor(np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])).unsqueeze(0).to(device).to(torch.float32)\n",
        "# codings = []\n",
        "# for num  in range(-10, 11):\n",
        "#     codings.append(initial_codings + coding_root * num)\n",
        "\n",
        "# codings = torch.stack(codings)\n",
        "# images = variational_ae.decoder(...\n",
        "# plot_multiple_images(images, 4)\n",
        "\n",
        "# random_codings = ..."
      ],
      "metadata": {
        "id": "GXdR4jmw_wtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w68oxFi3W_Y8"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "705Eee36W_Y8"
      },
      "source": [
        "Now let's perform semantic interpolation between these images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5B_qgEcW_Y9"
      },
      "source": [
        "# Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZaaKwEW_Y9"
      },
      "source": [
        "### Task 7:\n",
        "Look at the GAN implementation below.   \n",
        "a) Explain what a Generative Adversarial Network does.   \n",
        "b) Run the code below. During every epoch it plots a few images. Comment on the <br>\n",
        "\"progress\" from epoch 1 to 50. <br>\n",
        "The training takes a very long time, you can also simply go to [this link](https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb) <br>\n",
        "and look at the output under the section \"Generative Adversarial Networks\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfmWLs1HW_Y9"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSU6rE64W_Y9"
      },
      "source": [
        "Task 7 a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89CL1qxWW_Y9"
      },
      "source": [
        "Task 7b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T84dcb-W_Y9"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoeS_lkkW_Y9"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = nn.Sequential(\n",
        "    nn.Linear(codings_size, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 150),\n",
        "    nn.Linear(150, 28 * 28),\n",
        "    nn.Unflatten(1, (1, 28, 28)),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "discriminator = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 150),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(150, 100),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(100, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm6lPrK7W_Y9"
      },
      "outputs": [],
      "source": [
        "gan = nn.Sequential(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wBazV3nW_Y-"
      },
      "outputs": [],
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan\n",
        "    gan.to(device)\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    optimizer_gen = torch.optim.Adam(generator.parameters())\n",
        "    optimizer_disc = torch.optim.Adam(discriminator.parameters())\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for X_batch in dataset:  # Assuming dataset yields (images, labels)\n",
        "            X_batch = X_batch.to(device)\n",
        "            # Phase 1 - training the discriminator\n",
        "            noise = torch.randn(batch_size, codings_size, device=device)\n",
        "            generated_images = generator(noise)\n",
        "\n",
        "            X_fake_and_real = torch.cat([generated_images.squeeze(1), X_batch], dim=0)\n",
        "            y1 = torch.tensor([[0.]] * batch_size + [[1.]] * batch_size, device=device)\n",
        "\n",
        "            discriminator.zero_grad()\n",
        "            predictions = discriminator(X_fake_and_real)\n",
        "            loss_d = loss_fn(predictions, y1)\n",
        "            loss_d.backward()\n",
        "            optimizer_disc.step()\n",
        "\n",
        "            # Phase 2 - training the generator\n",
        "            noise = torch.randn(batch_size, codings_size, device=device)\n",
        "            y2 = torch.tensor([[1.]] * batch_size, device=device)\n",
        "\n",
        "            generator.zero_grad()\n",
        "            gen_images = generator(noise)\n",
        "            gen_pred = discriminator(gen_images)\n",
        "            loss_g = loss_fn(gen_pred, y2)\n",
        "            loss_g.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "        plot_multiple_images(generated_images.detach().cpu().numpy().squeeze(1), 8)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx6uDL5aW_Y-"
      },
      "outputs": [],
      "source": [
        "train_gan(gan, train_loader, batch_size, codings_size, n_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fGXZf-WW_Y-"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = torch.randn([batch_size, codings_size])\n",
        "generated_images = generator(noise.to(device))\n",
        "plot_multiple_images(generated_images.to('cpu').detach().numpy().squeeze(1), 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96UNVYGGW_Y-"
      },
      "source": [
        "# Deep Convolutional GAN\n",
        "This is the convolutional variant of the GAN. Again, you can simply look at <br>\n",
        "the ouptut from the [link](https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb). This model is large enough that it's not reasonable to <br>\n",
        "train on colab so just look at the outputs and compare.\n",
        "\n",
        "The section to look at in that link is also called **Deep Convolutional GAN**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj1cy-I7W_Y-"
      },
      "source": [
        "### Task 8:\n",
        "a) Comment on the training progress of the Deep Convolutional GAN.   \n",
        "b) Compare the results from the Deep Convolutional GAN with the results from <br>\n",
        "task 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5_UMYAzW_Y-"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuYe-Iu9W_Y_"
      },
      "source": [
        "Task 8 a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B6vdyS6W_Y_"
      },
      "source": [
        "Task 8b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKeBIkkVW_Y_"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 9 (Bonus): Model performance analysis\n",
        "\n",
        "Analyze the performance of at least 3 models used in this exercise using at <br>\n",
        "least two different metrics on the test data sets or newly generated data. <br>\n",
        "Examples of metrics might be mean-squared error, mean-absolute error, etc. <br>\n",
        "\n",
        "Further, provide a brief text description (less than 500 words) explaining the <br>\n",
        "metric used and results."
      ],
      "metadata": {
        "id": "bDTuLad08Bzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ],
      "metadata": {
        "id": "iT2iabKo8Bzo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Xpb1p238Bzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 9) answer:"
      ],
      "metadata": {
        "id": "dpf6qZRQ-TTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this"
      ],
      "metadata": {
        "id": "biRtG7Tr8Bzo"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
